{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 21688,
          "sourceType": "datasetVersion",
          "datasetId": 16432
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Exercise: Handling Missing Values",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'building-permit-applications-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F16432%2F21688%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240704%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240704T164141Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D79d782826a4674a6566cddd5a99cccf128fd1a93bc9d8de36eef69a009acc0ce874e8742e09c3264bb81f7afc37641c9244307a098519a04ac413f01b36e1bdbcc352f60784aee5badf2f024c7ecf24d87b0684a63f370d86863157b88cb4a13d1ed4edffc7fd461ee22d3416c2f8e97715a15aeb7a9a67643612b3b023b31641c1b606b651e27c1e2527e9f82a78048b98ab32ec7617cf25d9f352e842bebc47589a9de60a9e96258a13bc5b2973b256698ddd95c2481b9d3c157b23099a7ffce5c495d2b830eb6f6452c5268fd7e0c4121f1e9974a9182e481616f312eeea9f7fc2a5aa0b1ca38a332de9f85cc45f88724ad42091cfee86acfa5a371845ad4'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "691cBmprn4F6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/handling-missing-values).**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7af6qKEWn4F8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll apply what you learned in the **Handling missing values** tutorial.\n",
        "\n",
        "# Setup\n",
        "\n",
        "The questions below will give you feedback on your work. Run the following cell to set up the feedback system."
      ],
      "metadata": {
        "id": "2CbJwbRwn4F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.data_cleaning.ex1 import *\n",
        "print(\"Setup Complete\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:12:19.093978Z",
          "iopub.execute_input": "2024-07-04T15:12:19.094777Z",
          "iopub.status.idle": "2024-07-04T15:12:19.102051Z",
          "shell.execute_reply.started": "2024-07-04T15:12:19.094738Z",
          "shell.execute_reply": "2024-07-04T15:12:19.100526Z"
        },
        "trusted": true,
        "id": "UchtI9BDn4F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Take a first look at the data\n",
        "\n",
        "Run the next code cell to load in the libraries and dataset you'll use to complete the exercise."
      ],
      "metadata": {
        "id": "QY2VkjDon4F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in all our data\n",
        "sf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:12:27.209934Z",
          "iopub.execute_input": "2024-07-04T15:12:27.210411Z",
          "iopub.status.idle": "2024-07-04T15:12:29.383869Z",
          "shell.execute_reply.started": "2024-07-04T15:12:27.210376Z",
          "shell.execute_reply": "2024-07-04T15:12:29.382676Z"
        },
        "trusted": true,
        "id": "VTw9-QQyn4F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the code cell below to print the first five rows of the `sf_permits` DataFrame."
      ],
      "metadata": {
        "id": "aYCt95vfn4GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here!\n",
        "sf_permits.head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:12:53.813863Z",
          "iopub.execute_input": "2024-07-04T15:12:53.815285Z",
          "iopub.status.idle": "2024-07-04T15:12:53.843688Z",
          "shell.execute_reply.started": "2024-07-04T15:12:53.815236Z",
          "shell.execute_reply": "2024-07-04T15:12:53.842304Z"
        },
        "trusted": true,
        "id": "Eb_Wip0gn4GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf_permits.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:14:00.43835Z",
          "iopub.execute_input": "2024-07-04T15:14:00.43925Z",
          "iopub.status.idle": "2024-07-04T15:14:00.938597Z",
          "shell.execute_reply.started": "2024-07-04T15:14:00.439209Z",
          "shell.execute_reply": "2024-07-04T15:14:00.93747Z"
        },
        "trusted": true,
        "id": "rF_05n3pn4GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the dataset have any missing values?  Once you have an answer, run the code cell below to get credit for your work."
      ],
      "metadata": {
        "id": "eBHMi7Mxn4GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your answer (Run this code cell to receive credit!)\n",
        "q1.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:14:29.566934Z",
          "iopub.execute_input": "2024-07-04T15:14:29.567404Z",
          "iopub.status.idle": "2024-07-04T15:14:29.577662Z",
          "shell.execute_reply.started": "2024-07-04T15:14:29.567372Z",
          "shell.execute_reply": "2024-07-04T15:14:29.576333Z"
        },
        "trusted": true,
        "id": "aqYXkkUNn4GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line below will give you a hint\n",
        "#q1.hint()"
      ],
      "metadata": {
        "id": "dYivIuUBn4GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) How many missing data points do we have?\n",
        "\n",
        "What percentage of the values in the dataset are missing?  Your answer should be a number between 0 and 100.  (If 1/4 of the values in the dataset are missing, the answer is 25.)"
      ],
      "metadata": {
        "id": "ikQj7XKkn4GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here!\n",
        "total_missing = sf_permits.isnull().sum()\n",
        "\n",
        "# Calculating total number of values\n",
        "total_cells = sf_permits.shape[0]\n",
        "percent_missing = (total_missing/total_cells)*100\n",
        "\n",
        "# Check your answer\n",
        "q2.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:22:06.419046Z",
          "iopub.execute_input": "2024-07-04T15:22:06.419431Z",
          "iopub.status.idle": "2024-07-04T15:22:06.923292Z",
          "shell.execute_reply.started": "2024-07-04T15:22:06.419404Z",
          "shell.execute_reply": "2024-07-04T15:22:06.922134Z"
        },
        "trusted": true,
        "id": "pZ3a036an4GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q2.hint()\n",
        "#q2.solution()"
      ],
      "metadata": {
        "id": "tQGCGqSAn4GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Figure out why the data is missing\n",
        "\n",
        "Look at the columns **\"Street Number Suffix\"** and **\"Zipcode\"** from the [San Francisco Building Permits dataset](https://www.kaggle.com/aparnashastry/building-permit-applications-data). Both of these contain missing values.\n",
        "- Which, if either, are missing because they don't exist?\n",
        "- Which, if either, are missing because they weren't recorded?  \n",
        "\n",
        "Once you have an answer, run the code cell below."
      ],
      "metadata": {
        "id": "W2oGBq4On4GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the relevant columns\n",
        "\n",
        "print(sf_permits[['Street Number Suffix', 'Zipcode']])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T15:58:46.540152Z",
          "iopub.execute_input": "2024-07-04T15:58:46.540888Z",
          "iopub.status.idle": "2024-07-04T15:58:46.55318Z",
          "shell.execute_reply.started": "2024-07-04T15:58:46.540854Z",
          "shell.execute_reply": "2024-07-04T15:58:46.552031Z"
        },
        "trusted": true,
        "id": "5xUzuKY3n4GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of missing values in each column\n",
        "missing_values = sf_permits[['Street Number Suffix', 'Zipcode']].isnull().sum()\n",
        "\n",
        "print(missing_values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:00:56.272719Z",
          "iopub.execute_input": "2024-07-04T16:00:56.273116Z",
          "iopub.status.idle": "2024-07-04T16:00:56.292961Z",
          "shell.execute_reply.started": "2024-07-04T16:00:56.273087Z",
          "shell.execute_reply": "2024-07-04T16:00:56.291388Z"
        },
        "trusted": true,
        "id": "Mbwl7MTWn4GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze patterns and domain knowledge\n",
        "# Validate Assumptions with data analysis\n",
        "# Analize the street number suffix column\n",
        "\n",
        "street_number_suffix_unique_values = sf_permits['Street Number Suffix'].unique()\n",
        "print('Unique Values in street_number_suffix_unique_values: ')\n",
        "print(street_number_suffix_unique_values)\n",
        "\n",
        "# Analyze the zipcode column\n",
        "\n",
        "zipcode_unique_values = sf_permits['Zipcode'].unique()\n",
        "print(\"Unique Values in Zipcode: \")\n",
        "print(zipcode_unique_values )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:06:45.881641Z",
          "iopub.execute_input": "2024-07-04T16:06:45.88208Z",
          "iopub.status.idle": "2024-07-04T16:06:45.906723Z",
          "shell.execute_reply.started": "2024-07-04T16:06:45.882048Z",
          "shell.execute_reply": "2024-07-04T16:06:45.905384Z"
        },
        "trusted": true,
        "id": "U8I7SnDxn4GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your answer (Run this code cell to receive credit!)\n",
        "q3.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:09:21.348637Z",
          "iopub.execute_input": "2024-07-04T16:09:21.349098Z",
          "iopub.status.idle": "2024-07-04T16:09:21.359347Z",
          "shell.execute_reply.started": "2024-07-04T16:09:21.349062Z",
          "shell.execute_reply": "2024-07-04T16:09:21.358063Z"
        },
        "trusted": true,
        "id": "cwdHOGrOn4GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line below will give you a hint\n",
        "#q3.hint()"
      ],
      "metadata": {
        "id": "WGU7y-I0n4GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Drop missing values: rows\n",
        "\n",
        "If you removed all of the rows of `sf_permits` with missing values, how many rows are left?\n",
        "\n",
        "**Note**: Do not change the value of `sf_permits` when checking this.  "
      ],
      "metadata": {
        "id": "2_aLTDEdn4GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here!\n",
        "sf_permits\n",
        "# Print original number of rows\n",
        "original_row_count = sf_permits.shape[0]\n",
        "\n",
        "print(\"Original number of rows: \", original_row_count)\n",
        "\n",
        "sf_permits_cleaned = sf_permits.dropna()\n",
        "\n",
        "# Print the number of remaining rows\n",
        "\n",
        "remaining_row_count = sf_permits_cleaned.shape[0]\n",
        "\n",
        "print(\"Number of rows after cleaning: \", remaining_row_count)\n",
        "\n",
        "# Calculate and print number of rows removed\n",
        "\n",
        "rows_removed = original_row_count - remaining_row_count\n",
        "\n",
        "print(\"Number of row removed: \", rows_removed)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:21:31.843259Z",
          "iopub.execute_input": "2024-07-04T16:21:31.84364Z",
          "iopub.status.idle": "2024-07-04T16:21:32.341514Z",
          "shell.execute_reply.started": "2024-07-04T16:21:31.843615Z",
          "shell.execute_reply": "2024-07-04T16:21:32.34029Z"
        },
        "trusted": true,
        "id": "Y_IXPoO2n4GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have an answer, run the code cell below."
      ],
      "metadata": {
        "id": "QM4xsLNxn4GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your answer (Run this code cell to receive credit!)\n",
        "q4.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:21:42.202223Z",
          "iopub.execute_input": "2024-07-04T16:21:42.202639Z",
          "iopub.status.idle": "2024-07-04T16:21:42.21248Z",
          "shell.execute_reply.started": "2024-07-04T16:21:42.20261Z",
          "shell.execute_reply": "2024-07-04T16:21:42.211168Z"
        },
        "trusted": true,
        "id": "w0NLfyLvn4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line below will give you a hint\n",
        "#q4.hint()"
      ],
      "metadata": {
        "id": "OPgLyga9n4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Drop missing values: columns\n",
        "\n",
        "Now try removing all the columns with empty values.  \n",
        "- Create a new DataFrame called `sf_permits_with_na_dropped` that has all of the columns with empty values removed.  \n",
        "- How many columns were removed from the original `sf_permits` DataFrame? Use this number to set the value of the `dropped_columns` variable below."
      ],
      "metadata": {
        "id": "ZVJcKLEqn4GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here\n",
        "sf_permits_with_na_dropped = sf_permits.dropna(axis=1)\n",
        "\n",
        "# print the remaining number of columns\n",
        "\n",
        "remaining_column_count = sf_permits_with_na_dropped.shape[1]\n",
        "print(\"Number of columns after removing columns with missing values: \", remaining_column_count )\n",
        "\n",
        "dropped_columns = sf_permits_with_na_dropped-remaining_column_count\n",
        "print(\"Dropped coulumns: \", dropped_columns)\n",
        "\n",
        "# Check your answer\n",
        "q5.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:31:31.617901Z",
          "iopub.execute_input": "2024-07-04T16:31:31.618322Z",
          "iopub.status.idle": "2024-07-04T16:31:32.575643Z",
          "shell.execute_reply.started": "2024-07-04T16:31:31.618292Z",
          "shell.execute_reply": "2024-07-04T16:31:32.573787Z"
        },
        "trusted": true,
        "id": "U3xPDs9gn4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q5.hint()\n",
        "#q5.solution()"
      ],
      "metadata": {
        "id": "qHUK7P26n4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Fill in missing values automatically\n",
        "\n",
        "Try replacing all the NaN's in the `sf_permits` data with the one that comes directly after it and then replacing any remaining NaN's with 0.  Set the result to a new DataFrame `sf_permits_with_na_imputed`."
      ],
      "metadata": {
        "id": "x-qjuZHQn4GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "sf_permits\n",
        "# Separate the dataset into numeric and categorical columns\n",
        "numeric_cols = sf_permits.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = sf_permits.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create an imputer for numeric columns (using mean)\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "sf_permits[numeric_cols] = numeric_imputer.fit_transform(sf_permits[numeric_cols])\n",
        "\n",
        "# Create an imputer for categorical columns (using most frequent)\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "sf_permits[categorical_cols] = categorical_imputer.fit_transform(sf_permits[categorical_cols])\n",
        "\n",
        "# The DataFrame with imputed values\n",
        "sf_permits_with_na_imputed = sf_permits\n",
        "\n",
        "# Optionally, save the new DataFrame to a CSV file\n",
        "sf_permits_with_na_imputed.to_csv('Building_Permits_with_Imputed_Values.csv', index=False)\n",
        "\n",
        "# Print a summary to verify the changes\n",
        "print(f\"Number of missing values in each column after imputation:\\n{sf_permits_with_na_imputed.isnull().sum()}\")\n",
        "\n",
        "\n",
        "# Check your answer\n",
        "q6.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T16:38:00.900682Z",
          "iopub.execute_input": "2024-07-04T16:38:00.901164Z",
          "iopub.status.idle": "2024-07-04T16:38:12.308876Z",
          "shell.execute_reply.started": "2024-07-04T16:38:00.90113Z",
          "shell.execute_reply": "2024-07-04T16:38:12.307697Z"
        },
        "trusted": true,
        "id": "j1YeCkvqn4GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q6.hint()\n",
        "#q6.solution()"
      ],
      "metadata": {
        "id": "ylHu2YCZn4GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More practice\n",
        "\n",
        "If you're looking for more practice handling missing values:\n",
        "\n",
        "* Check out [this noteboook](https://www.kaggle.com/alexisbcook/missing-values) on handling missing values using scikit-learn's imputer.\n",
        "* Look back at the \"Zipcode\" column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset. You can search for datasets about San Fransisco on the [Datasets listing](https://www.kaggle.com/datasets).)\n",
        "\n",
        "# Keep going\n",
        "\n",
        "In the next lesson, learn how to [**apply scaling and normalization**](https://www.kaggle.com/alexisbcook/scaling-and-normalization) to transform your data."
      ],
      "metadata": {
        "id": "jbwKQ-vrn4GJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"
      ],
      "metadata": {
        "id": "FCtf8i2un4GJ"
      }
    }
  ]
}